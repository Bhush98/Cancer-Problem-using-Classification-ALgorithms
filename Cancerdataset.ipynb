{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different model accuracy scores on Cancer Dataset\n",
    "# in this part we have used\n",
    "# 1:Logistic Regression\n",
    "# 2:K nearest neighbors\n",
    "# 3:SVM using linear kernel\n",
    "# 4:Decision Tree\n",
    "# 5:Naive Bayes\n",
    "# 6:Random Forest\n",
    "# 7:Gradient boosting Classifier\n",
    "\n",
    "\n",
    "#initializing the libraries that we need\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting out data in out cancer Dataframe\n",
    "# as well as cleaning the data\n",
    "\n",
    "Cancer_dataset = pd.read_csv('Downloads/data.csv')\n",
    "Cancer_dataset.dropna()\n",
    "Cancer_dataset.replace('?',-99999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the first five instances of our dataframe\n",
    "\n",
    "Cancer_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our Features that is our x data\n",
    "\n",
    "X_cancer = Cancer_dataset[['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean',\n",
    "                           'compactness_mean','concavity_mean','concave points_mean','texture_worst',\n",
    "                           'perimeter_worst','area_worst','smoothness_worst','compactness_worst',\n",
    "                           'concavity_worst','concave points_worst','symmetry_worst',\n",
    "                           'fractal_dimension_worst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our outcome that is our y data\n",
    "\n",
    "Y_cancer = Cancer_dataset['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing\n",
    "\n",
    "X_train,x_test,Y_train,y_test = train_test_split(X_cancer,Y_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the normalized training data: [[0.3028539  0.86617583 0.29403635 0.1754825  0.35948361 0.16833323\n",
      "  0.06611163 0.17062206 0.78374693 0.23048957 0.12790012 0.31264009\n",
      "  0.12608032 0.0598547  0.26676976 0.14971483 0.23064568]\n",
      " [0.11940934 0.07449112 0.11436666 0.05531283 0.44930938 0.13968468\n",
      "  0.06932458 0.10852065 0.07608399 0.07331042 0.03187672 0.41587992\n",
      "  0.09610042 0.07578632 0.21398625 0.21007605 0.24113931]\n",
      " [0.38567845 0.82676483 0.36569691 0.24432662 0.27597725 0.0818048\n",
      "  0.10989681 0.14317825 0.65557677 0.29727576 0.1833956  0.29633906\n",
      "  0.07837603 0.13222222 0.22594502 0.39615019 0.06895813]\n",
      " [0.36485399 0.14118666 0.37613157 0.21743372 0.45562878 0.50371143\n",
      "  0.34005629 0.32932567 0.14916826 0.31719707 0.15336217 0.4077294\n",
      "  0.36921404 0.27512821 0.38075601 0.2996673  0.39479602]\n",
      " [0.26925079 0.28497185 0.25886255 0.14693531 0.45292047 0.1756334\n",
      "  0.07488274 0.11014114 0.22443414 0.19069675 0.09565474 0.45663248\n",
      "  0.10312867 0.08717949 0.19250859 0.26663498 0.14637541]\n",
      " [0.28486914 0.48072759 0.30205238 0.15961824 0.67409949 0.53315748\n",
      "  0.43597561 0.48891793 0.48704663 0.27785248 0.13618266 0.67330028\n",
      "  0.56314998 0.46068376 0.70790378 0.66825095 0.55669772]\n",
      " [0.57641157 0.68774361 0.5694838  0.42184517 0.44569829 0.38623397\n",
      "  0.45051595 0.50517512 0.62803382 0.54479805 0.37819505 0.72695782\n",
      "  0.39183624 0.49179487 0.64329897 0.40209125 0.44961987]]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the data for creating different features\n",
    "# normalizing is used when all the features are relatively close to the space \n",
    "# We are using MinMax Scaling here another one is polynomial\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "new_x_train = scaler.transform(X_train)\n",
    "new_x_test = scaler.transform(x_test)\n",
    "print('This is the normalized training data:',new_x_train[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the normalized testing data: [[0.21198353 0.32221741 0.2059291  0.11011665 0.32409497 0.17655359\n",
      "  0.07842402 0.07851542 0.23834197 0.16076498 0.07486237 0.29362222\n",
      "  0.16649279 0.10478632 0.18931271 0.15256654 0.2266838 ]\n",
      " [0.34260968 0.53702902 0.34952664 0.19783669 0.49535073 0.68069444\n",
      "  0.46458724 0.34594877 0.66293973 0.27884855 0.14186001 0.55783468\n",
      "  0.99428954 0.72547009 0.60893471 0.85551331 0.95716886]\n",
      " [0.45051825 0.32784755 0.43404049 0.29463415 0.39929584 0.20029446\n",
      "  0.13747655 0.25274438 0.34305972 0.33263609 0.20246756 0.42538885\n",
      "  0.15441298 0.14213675 0.31350515 0.19676806 0.1015098 ]\n",
      " [0.21860949 0.59636206 0.21035174 0.11609756 0.19960278 0.11502362\n",
      "  0.04629456 0.06863565 0.51131715 0.15429055 0.07159359 0.16491204\n",
      "  0.11949133 0.06187179 0.16546392 0.39876426 0.13106328]\n",
      " [0.41265559 0.41533131 0.39672448 0.26430541 0.39126117 0.21044721\n",
      "  0.15462008 0.27124935 0.54404145 0.39289805 0.26636846 0.47700876\n",
      "  0.35955019 0.24803419 0.52955326 0.44462928 0.3330121 ]\n",
      " [0.23470112 0.32568211 0.22057909 0.1247508  0.2706509  0.08628305\n",
      "  0.04624765 0.07051751 0.2307063  0.1656457  0.08405427 0.29362222\n",
      "  0.06783365 0.07865812 0.21635739 0.28968631 0.20205589]\n",
      " [0.29764778 0.17496752 0.28297975 0.17314952 0.1888598  0.09560763\n",
      "  0.07647749 0.13842133 0.25852195 0.26938593 0.15862171 0.19989133\n",
      "  0.1059839  0.11538462 0.34398625 0.10955323 0.07334832]]\n"
     ]
    }
   ],
   "source": [
    "print('This is the normalized testing data:',new_x_test[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 : Logistic Regression \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(new_x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of Logistic Regression is : 0.9577464788732394\n",
      "The testing accuracy of Logistic Regression is : 0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "print('The training accuracy of Logistic Regression is :',clf.score(new_x_train,Y_train))\n",
    "print('The testing accuracy of Logistic Regression is :',clf.score(new_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 : KNN(K nearest neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf2 = KNeighborsClassifier(n_neighbors = 10)\n",
    "clf2.fit(new_x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of KNN is : 0.9647887323943662\n",
      "The testing accuracy of KNN is : 0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "print('The training accuracy of KNN is :',clf2.score(new_x_train,Y_train))\n",
    "print('The testing accuracy of KNN is :',clf2.score(new_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 : SVM using kernel as linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=5, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf3 = SVC(kernel='linear',gamma=5)\n",
    "clf3.fit(new_x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of SVM is : 0.971830985915493\n",
      "The testing accuracy of SVM is : 0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "print('The training accuracy of SVM is :',clf3.score(new_x_train,Y_train))\n",
    "print('The testing accuracy of SVM is :',clf3.score(new_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 : Decision trees\n",
    " \n",
    "    \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf4 = DecisionTreeClassifier(max_depth=12)\n",
    "clf4.fit(new_x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of Decision Tree is : 1.0\n",
      "The testing accuracy of Decision Tree is : 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "print('The training accuracy of Decision Tree is :',clf4.score(new_x_train,Y_train))\n",
    "print('The testing accuracy of Decision Tree is :',clf4.score(new_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 : Naive Bayes\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf5 = GaussianNB()\n",
    "clf5.fit(new_x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of Gaussian Naive Bayes is : 0.9295774647887324\n",
      "The testing accuracy of Gaussian Naive Bayes is : 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "print('The training accuracy of Gaussian Naive Bayes is :',clf5.score(new_x_train,Y_train))\n",
    "print('The testing accuracy of Gaussian Naive Bayes is :',clf5.score(new_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 : Random Forests\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf6 = RandomForestClassifier(n_estimators = 15)\n",
    "clf6.fit(new_x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of Random Forest is : 1.0\n",
      "The testing accuracy of Random Forest is : 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "print('The training accuracy of Random Forest is :',clf6.score(new_x_train,Y_train))\n",
    "print('The testing accuracy of Random Forest is :',clf6.score(new_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7 : Gradient boosted Decision Tree\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf7 = GradientBoostingClassifier(n_estimators = 10,learning_rate = 0.1)\n",
    "clf7.fit(new_x_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of Gradient Boosted Classifier is : 0.9906103286384976\n",
      "The testing accuracy of Gradient Boosted Classifier is : 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "print('The training accuracy of Gradient Boosted Classifier is :',clf7.score(new_x_train,Y_train))\n",
    "print('The testing accuracy of Gradient Boosted Classifier is :',clf7.score(new_x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
